{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d37f089",
   "metadata": {},
   "outputs": [],
   "source": [
    "#punya hans\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# --- 1. FUNGSI UNTUK MENGAMBIL DATA DARI SATU HALAMAN HTML ---\n",
    "def parse_laptop_data(html_content):\n",
    "    \"\"\"\n",
    "    Mengurai data laptop dari konten HTML yang diberikan (halaman tunggal).\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    data_laptop = []\n",
    "\n",
    "    # Cari semua elemen 'li' yang berisi data laptop.\n",
    "    # Elemen ini adalah pembungkus untuk setiap produk laptop.\n",
    "    laptop_listings = soup.find_all('li', class_='flex items-center gap-2 list-none border-b py-1 mb-2')\n",
    "\n",
    "    for listing in laptop_listings:\n",
    "        # Awalnya, cari tag <a> yang berisi nama dan detail laptop\n",
    "        main_link = listing.find('a', class_=re.compile(r\"grid-cols-laptopLayoutSmall\"))\n",
    "        if not main_link:\n",
    "            continue\n",
    "        \n",
    "        # 1. Nama Laptop (berada di tag <h2> di dalam <a>)\n",
    "        name_el = main_link.find('h2')\n",
    "        name = name_el.get_text(strip=True) if name_el else 'N/A'\n",
    "        \n",
    "        # 2. Detail Spesifikasi (berada di tag <dl> di dalam <a>)\n",
    "        specs = {}\n",
    "        specs_container = main_link.find('dl')\n",
    "        if specs_container:\n",
    "            # Menggunakan dt (deskripsi term) dan dd (deskripsi detail) untuk mengekstrak spesifikasi\n",
    "            dt_elements = specs_container.find_all('dt')\n",
    "            dd_elements = specs_container.find_all('dd')\n",
    "            \n",
    "            # Map the specification details based on the <dt> tag content\n",
    "            for dt, dd in zip(dt_elements, dd_elements):\n",
    "                key = dt.get_text(strip=True).replace(':', '') \n",
    "                value = dd.get_text(strip=True)\n",
    "                specs[key] = value\n",
    "\n",
    "        # 3. Harga Jual\n",
    "        price_el = listing.find('div', class_='priceBtn').find('span', class_='text-lm-darkBlue')\n",
    "        price_raw = price_el.get_text(strip=True) if price_el else 'N/A'\n",
    "        price_cleaned = re.sub(r'[$,€]', '', price_raw).replace(' ', '').replace('sup', '') # Membersihkan simbol mata uang dan spasi\n",
    "\n",
    "        # 4. Link ke Halaman Detail Produk\n",
    "        detail_url = main_link['href'] if main_link and 'href' in main_link.attrs else 'N/A'\n",
    "\n",
    "        # 5. Link Beli (ke Amazon)\n",
    "        buy_link_el = listing.find('a', target='_blank', href=re.compile(r'amazon\\.com'))\n",
    "        buy_link = buy_link_el['href'] if buy_link_el else 'N/A'\n",
    "        \n",
    "        data_laptop.append({\n",
    "            'Nama_Laptop': name,\n",
    "            'Processor': specs.get('Processor', 'N/A'),\n",
    "            'RAM': specs.get('Internal memory', 'N/A'),\n",
    "            'GPU': specs.get('Video card', 'N/A'),\n",
    "            'Display': specs.get('Display', 'N/A'),\n",
    "            # Menggabungkan SSD dan HDD karena keduanya menggunakan class 'storage'\n",
    "            'Storage': specs.get('Solid-state drive', '') + ' ' + specs.get('Hard drive', ''),\n",
    "            'Harga_USD': price_cleaned,\n",
    "            'Detail_URL': detail_url,\n",
    "            'Buy_Link': buy_link,\n",
    "        })\n",
    "\n",
    "    return data_laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a6ee9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ EKSTRAKSI DATA DARI HALAMAN 1 SUKSES ================\n",
      "Data berhasil disimpan ke laptop_data_scraped.csv\n",
      "Total Data Laptop yang Diekstrak: 1000\n",
      "\n",
      "Berikut 5 baris pertama dari data yang diekstrak:\n",
      "                 Nama_Laptop                Processor       RAM  \\\n",
      "0        Alienware 16 Aurora        Intel Core 7 240H  24GB RAM   \n",
      "1  Lenovo ThinkBook 16 Gen 8        Intel Core 7 240H  16GB RAM   \n",
      "2           Lenovo V15 Gen 4        AMD Ryzen 7 7730U  12GB RAM   \n",
      "3  Lenovo ThinkPad T16 Gen 3  Intel Core Ultra 7 155H  16GB RAM   \n",
      "4   Samsung Galaxy Book4 360        Intel Core 7 150U  16GB RAM   \n",
      "\n",
      "                                      GPU  \\\n",
      "0        NVIDIA GeForce RTX 5050 (Laptop)   \n",
      "1   Intel UHD Graphics (Alder Lake, 64EU)   \n",
      "2  AMD Radeon RX Vega 8 (R4000/5000, 15W)   \n",
      "3                     Intel Arc (8-Cores)   \n",
      "4        Intel Iris Xe Graphics G7 (96EU)   \n",
      "\n",
      "                                   Display     Storage Harga_USD  \\\n",
      "0  16.0\", WQXGA (2560 x 1600), 120 Hz, IPS  1000GB SSD    124900   \n",
      "1          16.0”, WUXGA (1920 x 1200), IPS  2000GB SSD    127900   \n",
      "2         15.6”, Full HD (1920 x 1080), TN   512GB SSD     56900   \n",
      "3          16.0”, WUXGA (1920 x 1200), IPS   512GB SSD    119900   \n",
      "4           15.6”, FHD (1920 x 1080), OLED  2000GB SSD    106099   \n",
      "\n",
      "                                          Detail_URL  \\\n",
      "0  https://laptopmedia.com/laptop-specs/alienware...   \n",
      "1  https://laptopmedia.com/laptop-specs/lenovo-th...   \n",
      "2  https://laptopmedia.com/laptop-specs/lenovo-v1...   \n",
      "3  https://laptopmedia.com/laptop-specs/lenovo-th...   \n",
      "4  https://laptopmedia.com/laptop-specs/samsung-g...   \n",
      "\n",
      "                                            Buy_Link  \n",
      "0  https://www.amazon.com/exec/obidos/ASIN/B0FVFL...  \n",
      "1  https://www.amazon.com/exec/obidos/ASIN/B0F9NX...  \n",
      "2  https://www.amazon.com/exec/obidos/ASIN/B0DM8V...  \n",
      "3  https://www.amazon.com/exec/obidos/ASIN/B0FRF7...  \n",
      "4  https://www.amazon.com/exec/obidos/ASIN/B0FHQ2...  \n",
      "                 Nama_Laptop                Processor       RAM  \\\n",
      "0        Alienware 16 Aurora        Intel Core 7 240H  24GB RAM   \n",
      "1  Lenovo ThinkBook 16 Gen 8        Intel Core 7 240H  16GB RAM   \n",
      "2           Lenovo V15 Gen 4        AMD Ryzen 7 7730U  12GB RAM   \n",
      "3  Lenovo ThinkPad T16 Gen 3  Intel Core Ultra 7 155H  16GB RAM   \n",
      "4   Samsung Galaxy Book4 360        Intel Core 7 150U  16GB RAM   \n",
      "\n",
      "                                      GPU  \\\n",
      "0        NVIDIA GeForce RTX 5050 (Laptop)   \n",
      "1   Intel UHD Graphics (Alder Lake, 64EU)   \n",
      "2  AMD Radeon RX Vega 8 (R4000/5000, 15W)   \n",
      "3                     Intel Arc (8-Cores)   \n",
      "4        Intel Iris Xe Graphics G7 (96EU)   \n",
      "\n",
      "                                   Display     Storage Harga_USD  \\\n",
      "0  16.0\", WQXGA (2560 x 1600), 120 Hz, IPS  1000GB SSD    124900   \n",
      "1          16.0”, WUXGA (1920 x 1200), IPS  2000GB SSD    127900   \n",
      "2         15.6”, Full HD (1920 x 1080), TN   512GB SSD     56900   \n",
      "3          16.0”, WUXGA (1920 x 1200), IPS   512GB SSD    119900   \n",
      "4           15.6”, FHD (1920 x 1080), OLED  2000GB SSD    106099   \n",
      "\n",
      "                                          Detail_URL  \\\n",
      "0  https://laptopmedia.com/laptop-specs/alienware...   \n",
      "1  https://laptopmedia.com/laptop-specs/lenovo-th...   \n",
      "2  https://laptopmedia.com/laptop-specs/lenovo-v1...   \n",
      "3  https://laptopmedia.com/laptop-specs/lenovo-th...   \n",
      "4  https://laptopmedia.com/laptop-specs/samsung-g...   \n",
      "\n",
      "                                            Buy_Link  \n",
      "0  https://www.amazon.com/exec/obidos/ASIN/B0FVFL...  \n",
      "1  https://www.amazon.com/exec/obidos/ASIN/B0F9NX...  \n",
      "2  https://www.amazon.com/exec/obidos/ASIN/B0DM8V...  \n",
      "3  https://www.amazon.com/exec/obidos/ASIN/B0FRF7...  \n",
      "4  https://www.amazon.com/exec/obidos/ASIN/B0FHQ2...  \n"
     ]
    }
   ],
   "source": [
    "# Menerapkan dan menjalankan fungsi parsing\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# (Definition of parse_laptop_data function is placed here before running)\n",
    "\n",
    "# Membaca konten dari file 'halaman1.html'\n",
    "file_name = 'halaman1.html'\n",
    "with open(file_name, 'r', encoding='utf-8') as f:\n",
    "    html_content = f.read()\n",
    "\n",
    "data_final = parse_laptop_data(html_content)\n",
    "\n",
    "# Menyimpan data ke DataFrame dan CSV\n",
    "if data_final:\n",
    "    df = pd.DataFrame(data_final)\n",
    "    # Membersihkan kolom Storage yang mungkin memiliki spasi ganda dari penggabungan\n",
    "    df['Storage'] = df['Storage'].str.strip().replace(r'\\s+', ' ', regex=True)\n",
    "    \n",
    "    output_file = 'laptop_data_scraped.csv'\n",
    "    df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(\"\\n================ EKSTRAKSI DATA DARI HALAMAN 1 SUKSES ================\")\n",
    "    print(f\"Data berhasil disimpan ke {output_file}\")\n",
    "    print(f\"Total Data Laptop yang Diekstrak: {len(df)}\")\n",
    "    print(\"\\nBerikut 5 baris pertama dari data yang diekstrak:\")\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(\"Tidak ada data laptop yang ditemukan.\")\n",
    "\n",
    "# Output the dataframe for review\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cb78595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ EKSTRAKSI DATA DARI HALAMAN 1 SUKSES ================\n",
      "Total Data Laptop yang Diekstrak: 1000\n",
      "\n",
      "Berikut 5 baris pertama dari data yang diekstrak:\n",
      "                 Nama_Laptop Harga_USD                Processor       RAM  \\\n",
      "0        Alienware 16 Aurora    124900        Intel Core 7 240H  24GB RAM   \n",
      "1  Lenovo ThinkBook 16 Gen 8    127900        Intel Core 7 240H  16GB RAM   \n",
      "2           Lenovo V15 Gen 4     56900        AMD Ryzen 7 7730U  12GB RAM   \n",
      "3  Lenovo ThinkPad T16 Gen 3    119900  Intel Core Ultra 7 155H  16GB RAM   \n",
      "4   Samsung Galaxy Book4 360    106099        Intel Core 7 150U  16GB RAM   \n",
      "\n",
      "                                      GPU  \\\n",
      "0        NVIDIA GeForce RTX 5050 (Laptop)   \n",
      "1   Intel UHD Graphics (Alder Lake, 64EU)   \n",
      "2  AMD Radeon RX Vega 8 (R4000/5000, 15W)   \n",
      "3                     Intel Arc (8-Cores)   \n",
      "4        Intel Iris Xe Graphics G7 (96EU)   \n",
      "\n",
      "                                   Display     Storage  \\\n",
      "0  16.0\", WQXGA (2560 x 1600), 120 Hz, IPS  1000GB SSD   \n",
      "1          16.0”, WUXGA (1920 x 1200), IPS  2000GB SSD   \n",
      "2         15.6”, Full HD (1920 x 1080), TN   512GB SSD   \n",
      "3          16.0”, WUXGA (1920 x 1200), IPS   512GB SSD   \n",
      "4           15.6”, FHD (1920 x 1080), OLED  2000GB SSD   \n",
      "\n",
      "                                          Detail_URL  \\\n",
      "0  https://laptopmedia.com/laptop-specs/alienware...   \n",
      "1  https://laptopmedia.com/laptop-specs/lenovo-th...   \n",
      "2  https://laptopmedia.com/laptop-specs/lenovo-v1...   \n",
      "3  https://laptopmedia.com/laptop-specs/lenovo-th...   \n",
      "4  https://laptopmedia.com/laptop-specs/samsung-g...   \n",
      "\n",
      "                                            Buy_Link  \n",
      "0  https://www.amazon.com/exec/obidos/ASIN/B0FVFL...  \n",
      "1  https://www.amazon.com/exec/obidos/ASIN/B0F9NX...  \n",
      "2  https://www.amazon.com/exec/obidos/ASIN/B0DM8V...  \n",
      "3  https://www.amazon.com/exec/obidos/ASIN/B0FRF7...  \n",
      "4  https://www.amazon.com/exec/obidos/ASIN/B0FHQ2...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def parse_laptop_data(html_content):\n",
    "    \"\"\"\n",
    "    Mengurai data laptop dari konten HTML yang diberikan (halaman tunggal).\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    data_laptop = []\n",
    "\n",
    "    # Target utama adalah setiap item <li> yang berisi data laptop\n",
    "    # Class: flex items-center gap-2 list-none border-b py-1 mb-2\n",
    "    #\n",
    "    laptop_listings = soup.find_all('li', class_=re.compile(r\"flex items-center.*border-b\"))\n",
    "\n",
    "    for listing in laptop_listings:\n",
    "        # Cari tag <a> di dalam <li>, yang berisi detail spesifikasi dan link\n",
    "        main_link = listing.find('a', class_=re.compile(r\"grid-cols-laptopLayoutSmall\"))\n",
    "        if not main_link:\n",
    "            continue\n",
    "        \n",
    "        # 1. Nama Laptop (berada di tag <h2>)\n",
    "        name_el = main_link.find('h2')\n",
    "        name = name_el.get_text(strip=True) if name_el else 'N/A'\n",
    "        \n",
    "        # 2. Detail Spesifikasi (berada di tag <dl>)\n",
    "        specs = {}\n",
    "        specs_container = main_link.find('dl')\n",
    "        if specs_container:\n",
    "            # Mengambil semua <dt> dan <dd> di dalam <dl>\n",
    "            dt_elements = specs_container.find_all('dt')\n",
    "            dd_elements = specs_container.find_all('dd')\n",
    "            \n",
    "            for dt, dd in zip(dt_elements, dd_elements):\n",
    "                # Membersihkan nama spesifikasi (misalnya 'Processor' dari '<dt class=\"sr-only\">Processor</dt>')\n",
    "                key = dt.get_text(strip=True).replace(':', '') \n",
    "                value = dd.get_text(strip=True)\n",
    "                specs[key] = value\n",
    "\n",
    "        # 3. Harga Jual dan Link Beli\n",
    "        price_btn = listing.find('div', class_='priceBtn')\n",
    "        price_el = price_btn.find('span', class_='text-lm-darkBlue') if price_btn else None\n",
    "        \n",
    "        # Membersihkan harga dari simbol mata uang ($) dan tag <sup>\n",
    "        price_raw = price_el.get_text(strip=True) if price_el else 'N/A'\n",
    "        price_cleaned = re.sub(r'[$,€\\s]', '', price_raw).split('sup')[0] \n",
    "        \n",
    "        # Link ke Halaman Detail Produk\n",
    "        detail_url = main_link['href'] if main_link and 'href' in main_link.attrs else 'N/A'\n",
    "\n",
    "        # Link Beli (ke Amazon)\n",
    "        buy_link_el = listing.find('a', target='_blank', href=re.compile(r'amazon\\.com'))\n",
    "        buy_link = buy_link_el['href'] if buy_link_el else 'N/A'\n",
    "        \n",
    "        # Menggabungkan semua data\n",
    "        data_laptop.append({\n",
    "            'Nama_Laptop': name,\n",
    "            'Harga_USD': price_cleaned,\n",
    "            'Processor': specs.get('Processor', 'N/A'),\n",
    "            'RAM': specs.get('Internal memory', 'N/A'),\n",
    "            'GPU': specs.get('Video card', 'N/A'),\n",
    "            'Display': specs.get('Display', 'N/A'),\n",
    "            # Menggabungkan SSD dan HDD karena keduanya menggunakan class 'storage'\n",
    "            'Storage': f\"{specs.get('Solid-state drive', '')} {specs.get('Hard drive', '')}\".strip(),\n",
    "            'Detail_URL': detail_url,\n",
    "            'Buy_Link': buy_link,\n",
    "        })\n",
    "\n",
    "    return data_laptop\n",
    "\n",
    "# --- Eksekusi pada file lokal ---\n",
    "# Membaca konten dari file 'halaman1.html'\n",
    "file_name = 'halaman1.html'\n",
    "with open(file_name, 'r', encoding='utf-8') as f:\n",
    "    html_content = f.read()\n",
    "\n",
    "data_halaman1 = parse_laptop_data(html_content)\n",
    "df_halaman1 = pd.DataFrame(data_halaman1)\n",
    "\n",
    "print(\"\\n================ EKSTRAKSI DATA DARI HALAMAN 1 SUKSES ================\")\n",
    "print(f\"Total Data Laptop yang Diekstrak: {len(df_halaman1)}\")\n",
    "print(\"\\nBerikut 5 baris pertama dari data yang diekstrak:\")\n",
    "print(df_halaman1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ba9e7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import undetected_chromedriver as uc\n",
    "import time \n",
    "\n",
    "def scrape_multi_page(base_url, total_pages):\n",
    "    all_laptop_data = []\n",
    "    \n",
    "    # Inisialisasi driver (undetected_chromedriver akan otomatis mendownload driver)\n",
    "    # use_subprocess=False dan headless=True adalah opsi yang umum digunakan\n",
    "    # Anda mungkin perlu menguji opsi ini. Hapus 'headless=True' jika ingin melihat browser.\n",
    "    driver = uc.Chrome(use_subprocess=False, headless=True)\n",
    "    \n",
    "    # Asumsi: Halaman 1 sudah kita scrap, kita mulai dari halaman 2\n",
    "    for page_num in range(1, total_pages + 1):\n",
    "        # Pola URL di situs ini biasanya seperti: https://laptopmedia.com/specs/page/2/?size=n_1000_n\n",
    "        url_halaman = f\"https://laptopmedia.com/specs/page/{page_num}/?size=n_1000_n\"\n",
    "        print(f\"Mengunjungi halaman: {url_halaman}\")\n",
    "        \n",
    "        try:\n",
    "            driver.get(url_halaman)\n",
    "            # Beri jeda waktu agar halaman memuat sempurna dan melewati anti-bot (jika ada)\n",
    "            time.sleep(5) \n",
    "            \n",
    "            # Ambil konten HTML yang sudah di-render oleh browser\n",
    "            html_content = driver.page_source\n",
    "            \n",
    "            # Panggil fungsi parsing yang sudah kita buat sebelumnya\n",
    "            data_halaman = parse_laptop_data(html_content)\n",
    "            \n",
    "            # Hentikan perulangan jika tidak ada data yang ditemukan (mencapai akhir halaman)\n",
    "            if not data_halaman:\n",
    "                print(\"Tidak ada data baru ditemukan. Menghentikan scraping.\")\n",
    "                break\n",
    "                \n",
    "            all_laptop_data.extend(data_halaman)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Terjadi error saat scraping halaman {page_num}: {e}\")\n",
    "            break\n",
    "\n",
    "    driver.quit() # Sangat penting untuk menutup driver setelah selesai\n",
    "    return all_laptop_data\n",
    "\n",
    "# --- Penggunaan ---\n",
    "# Ganti angka 5 dengan jumlah halaman yang ingin Anda ambil (atau angka yang sangat besar untuk semua halaman)\n",
    "# total_pages_to_scrape = 5 \n",
    "# final_data = scrape_multi_page(base_url=\"https://laptopmedia.com/specs/\", total_pages=total_pages_to_scrape)\n",
    "\n",
    "# df_final = pd.DataFrame(final_data)\n",
    "# df_final['Storage'] = df_final['Storage'].str.strip().replace(r'\\s+', ' ', regex=True)\n",
    "# df_final.to_csv('all_laptop_data.csv', index=False)\n",
    "# print(f\"\\nScraping selesai. Total data yang diekstrak: {len(df_final)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
